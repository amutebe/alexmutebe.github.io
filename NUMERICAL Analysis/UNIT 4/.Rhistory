summary(m_date$duration)
#Summary statistics for Age
summary(m_date$pdays)
m_date <- mutate(m_date,pdays5 = ifelse(pdays == 999,'',pdays))
m_date$pdays <- m_date$pdays5
#Summary statistics for Age
summary(m_date$pdays)
boxplot(m_date$previous)
summary(m_date$previous)
ggplot(m_date,mapping = aes(previous)) + geom_histogram()
boxplot(m_date$cons.conf.idx)
ggplot(m_date,mapping = aes(cons.conf.idx)) + geom_histogram(binwidth = 10)
summary(m_date$cons.conf.idx)
m_date <- mutate(m_date,shifted_cons.conf.idx = m_date$cons.conf.idx - min(m_date$cons.conf.idx) + 1)
#transformed_x <- log(shifted_x)
m_date <- mutate(m_date,log_cons.conf.idx = log(m_date$shifted_cons.conf.idx))
summary(m_date$log_cons.conf.idx)
boxplot(m_date$euribor3m)
ggplot(m_date,mapping = aes(euribor3m)) + geom_histogram(binwidth = 1)
summary(m_date$euribor3m)
boxplot(m_date$nr.employed)
ggplot(m_date,mapping = aes(nr.employed)) + geom_histogram(binwidth = 100)
#Numeric values statistics
m_date %>% summarize_if(is.numeric, mean)
plot(age ~ duration, data = m_date, col = "dodgerblue", pch = 20, cex = 1.5,
main = "age vs duration")
ggplot(m_date, mapping=(aes(y=job,fill=job))) + geom_bar()
ggplot(m_date, mapping=(aes(x=marital,fill=marital))) + geom_bar()
ggplot(m_date, mapping=(aes(y=k,fill=k))) + geom_bar()
ggplot(m_date, mapping=(aes(y=k,fill=k))) + geom_bar()
summary(m_date$k)
#view(filter(m_date2,k=="illiterate"))
#Deleting the row with illiterate value
m_date2 <- subset(m_date, k!="illiterate")
ggplot(m_date, mapping=(aes(x=housing,fill=housing))) + geom_bar()
summary(m_date$housing)
ggplot(m_date, mapping=(aes(x=loan,fill=loan))) + geom_bar()
summary(m_date$loan)
ggplot(m_date, mapping=(aes(x=contact,fill=contact))) + geom_bar()
summary(m_date$contact)
ggplot(m_date, mapping=(aes(x=month,fill=month))) + geom_bar()
summary(m_date$month)
ggplot(m_date, mapping=(aes(x=day_of_week,fill=day_of_week))) + geom_bar()
summary(m_date$day_of_week)
# Compute the chi-squared correlation matrix
df <- select_if(m_date, is.numeric)
# Compute the correlation matrix
cor_matrix <- cor(df)
# Plot the correlation matrix
corrplot(cor_matrix, method = "color", type = "lower", tl.cex = 1)
final_mm_dataset <- select(m_date,-c(shifted_cons.conf.idx,pdays5,cons.conf.idx,marital,poutcome))
# Compute the chi-squared correlation matrix
df <- select_if(final_mm_dataset, is.numeric)
# Compute the correlation matrix
cor_matrix <- cor(df)
# Plot the correlation matrix
corrplot(cor_matrix, method = "color", type = "lower", tl.cex = 1)
#add factor level called 'no region'
levels(m_date$marital) <- c(levels(m_date$marital), 'unknown')
#convert each NA to 'no region'
#df$region[is.na(df$region)] <- 'no region'
library(caret)
set.seed(350)
mm_train = createDataPartition(y = final_mm_dataset$y, times = 1, p = 0.7, list = FALSE)
train_set = slice(final_mm_dataset, mm_train)
test_set = slice(final_mm_dataset, -mm_train)
# Create a logistic regression model
model <- glm(y ~ ., data = train_set, family = binomial)
# Print the summary of the model
summary(model)
# Make predictions on the test set
predictions <- predict(model, newdata = test_set, type = "response")
# Convert predictions to binary values (0 or 1) using a threshold of 0.5
binary_predictions <- ifelse(predictions > 0.5, "yes", "no")
#GLM
#predict_heart_glm <- predict(glm_fit_heart, newdata = test_set, type = "response")
#new_predicted_heart <- ifelse(predict_heart_glm > 0.5, 1, 0)
heart_glm <- confusionMatrix(data = as.factor(binary_predictions), reference = as.factor(test_set$y), positive = "no")
heart_glm
library(pROC)
#calculate probabilities to construct the ROC
#GLM
roc_GLM <- roc(test_set$y, predictions)
print(roc_GLM)
plot(roc_GLM)
#Decision tree
library(rpart)
decision_trees_mm <- rpart(y ~ ., data = train_set, method = "class")
predict_decisiontrees <- predict(decision_trees_mm, newdata = test_set, type = c("class"))
mm_DecisionTree <- confusionMatrix(data = as.factor(predict_decisiontrees), reference = as.factor(test_set$y), positive = "no")
mm_DecisionTree
#Decision tree
decision_tree.preds <- predict(decision_trees_mm, test_set, type="prob")[, 2]
decision_tree <- roc(test_set$y, decision_tree.preds)
print(decision_tree)
plot(decision_tree)
ggplot(m_date,mapping = aes(cons.conf.idx)) + geom_histogram(binwidth = 10)
summary(m_date$cons.conf.idx)
m_date <- mutate(m_date,shifted_cons.conf.idx = m_date$cons.conf.idx - min(m_date$cons.conf.idx) + 1)
m_date <- mutate(m_date,shifted_cons.conf.idx = m_date$cons.conf.idx - min(m_date$cons.conf.idx) + 1)
#transformed_x <- log(shifted_x)
m_date <- mutate(m_date,log_cons.conf.idx = log(m_date$shifted_cons.conf.idx))
boxplot(m_date$euribor3m)
m_date <- mutate(m_date,pdays5 = ifelse(pdays == 999,'',pdays))
m_date <- mutate(m_date,pdays5 = ifelse(pdays == 999,'',pdays))
m_date$pdays <- m_date$pdays5
#Summary statistics for Age
summary(m_date$pdays)
m_date <- mutate(m_date,pdays5 = ifelse(m_date$pdays == 999,'',m_date$pdays))
mutate(m_date,pdays5 = ifelse(pdays == 999,'',pdays))
mutate(m_date,pdays5 = ifelse(pdays == 999,'',pdays))
m_date <- mutate(m_date,pdays5 = ifelse(pdays == 999,'',pdays))
#Box plot for visualising outliers
boxplot(m_date$age)
#Summary statistics for Age
summary(m_date$pdays)
sampled <- m_date[sample(1:nrow(m_date), 3), ]  # Sample rows of data with Base R
sampled
sampled <- m_date[sample(1:nrow(m_date), 10), ]  # Sample rows of data with Base R
sampled
knitr:: kable(
sampled <- m_date[sample(1:nrow(m_date), 10), ]  # Sample rows of data with Base R
sampled)
knitr:: kable(
sampled <- m_date[sample(1:nrow(m_date), 10), ] ) # Sample rows of data with Base R
sampled
knitr:: kable(
sampled <- m_date[sample(1:nrow(m_date), 10), ], caption = "Sampling 10 records" )
sampled
m_date$job <- as.factor(m_date$job)
m_date$marital <- as.factor(m_date$marital)
m_date$k <- as.factor(m_date$k)
m_date$default <- as.factor(m_date$default)
m_date$housing <- as.factor(m_date$housing)
m_date$loan <- as.factor(m_date$loan)
m_date$contact <- as.factor(m_date$contact)
m_date$month <- as.factor(m_date$month)
m_date$day_of_week <- as.factor(m_date$day_of_week)
m_date$poutcome <- as.factor(m_date$poutcome)
m_date$y <- as.factor(m_date$y)
#m_date$pdays2 <- as.factor(m_date$pdays)
m_date <- mutate(m_date,pdays5 = ifelse(pdays == 999,'',pdays))
# Compute the chi-squared correlation matrix
df <- select_if(m_date, is.numeric)
# Compute the correlation matrix
cor_matrix <- cor(df)
# Plot the correlation matrix
corrplot(cor_matrix, method = "color", type = "lower", tl.cex = 1)
df <- select_if(m_date, is.numeric)
mm_DecisionTree
rpart.plot(decision_tree)
library(rpart.plot)
rpart.plot(decision_tree)
install.packages("rpart.plot")
rpart.plot(decision_tree)
install.packages("rpart.plot")
rpart.plot(decision_tree)
rpart.plot(decision_tree)
plot(decision_tree)
rpart.plot(mm_DecisionTree)
plot(mm_DecisionTree)
decision_tree.preds <- predict(decision_trees_mm, test_set, type="prob")[, 2]
decision_tree <- roc(test_set$y, decision_tree.preds)
library(rpart)
library(rpart.plot)
decision_trees_mm <- rpart(y ~ ., data = train_set, method = "class")
predict_decisiontrees <- predict(decision_trees_mm, newdata = test_set, type = c("class"))
mm_DecisionTree <- confusionMatrix(data = as.factor(predict_decisiontrees), reference = as.factor(test_set$y), positive = "no")
mm_DecisionTree <- confusionMatrix(data = as.factor(predict_decisiontrees), reference = as.factor(test_set$y), positive = "no")
library(rpart)
library(rpart.plot)
decision_trees_mm <- rpart(y ~ ., data = train_set, method = "class")
predict_decisiontrees <- predict(decision_trees_mm, newdata = test_set, type = c("class"))
library(caret)
set.seed(350)
#partitioning the dataset i.e  70% train set and 30% for test set
mm_train = createDataPartition(y = final_mm_dataset$y, times = 1, p = 0.7, list = FALSE)
train_set = slice(final_mm_dataset, mm_train)
library(tidyverse)
setwd("D:/SCHULE/visualisation/jun24_assignment")
m_date <- read.csv("MMA marketing_data_sample.csv",header = TRUE)
#Import the tidyverse package for data visualisation and wrangling
library(tidyverse)
library(corrplot)
#Checking in with the first 10 records
knitr:: kable(
m_date[1:10,], caption = "Preview of Marketing Data subset with 10 rows"
)
knitr:: kable(
sampled <- m_date[sample(1:nrow(m_date), 10), ], caption = "Sampling 10 records" )
str(m_date)
sum(is.na(m_date))
m_date$job <- as.factor(m_date$job)
m_date$marital <- as.factor(m_date$marital)
m_date$k <- as.factor(m_date$k)
m_date$default <- as.factor(m_date$default)
m_date$housing <- as.factor(m_date$housing)
m_date$loan <- as.factor(m_date$loan)
m_date$contact <- as.factor(m_date$contact)
m_date$month <- as.factor(m_date$month)
m_date$day_of_week <- as.factor(m_date$day_of_week)
m_date$poutcome <- as.factor(m_date$poutcome)
m_date$y <- as.factor(m_date$y)
str(m_date)
boxplot(m_date$age)
ggplot(m_date,mapping = aes(age)) + geom_histogram(binwidth = 5)
summary(m_date$age)
boxplot(m_date$duration)
ggplot(m_date,mapping = aes(duration)) + geom_histogram(binwidth = 100)
#Summary statistics for Age
summary(m_date$duration)
#Summary statistics for Age
summary(m_date$pdays)
m_date <- mutate(m_date,pdays5 = ifelse(pdays == 999,'',pdays))
m_date$pdays <- m_date$pdays5
summary(m_date$pdays)
boxplot(m_date$previous)
summary(m_date$previous)
ggplot(m_date,mapping = aes(previous)) + geom_histogram()
boxplot(m_date$cons.conf.idx)
ggplot(m_date,mapping = aes(cons.conf.idx)) + geom_histogram(binwidth = 10)
summary(m_date$cons.conf.idx)
m_date <- mutate(m_date,shifted_cons.conf.idx = m_date$cons.conf.idx - min(m_date$cons.conf.idx) + 1)
m_date <- mutate(m_date,log_cons.conf.idx = log(m_date$shifted_cons.conf.idx))
summary(m_date$log_cons.conf.idx)
boxplot(m_date$euribor3m)
ggplot(m_date,mapping = aes(euribor3m)) + geom_histogram(binwidth = 1)
summary(m_date$euribor3m)
boxplot(m_date$nr.employed)
ggplot(m_date,mapping = aes(nr.employed)) + geom_histogram(binwidth = 100)
m_date %>% summarize_if(is.numeric, mean)
plot(age ~ duration, data = m_date, col = "dodgerblue", pch = 20, cex = 1.5,
main = "age vs duration")
ggplot(m_date, mapping=(aes(y=job,fill=job))) + geom_bar()
ggplot(m_date, mapping=(aes(x=marital,fill=marital))) + geom_bar()
ggplot(m_date, mapping=(aes(y=k,fill=k))) + geom_bar()
ggplot(m_date, mapping=(aes(y=k,fill=k))) + geom_bar()
summary(m_date$k)
m_date2 <- subset(m_date, k!="illiterate")
ggplot(m_date, mapping=(aes(x=housing,fill=housing))) + geom_bar()
summary(m_date$housing)
ggplot(m_date, mapping=(aes(x=loan,fill=loan))) + geom_bar()
summary(m_date$loan)
ggplot(m_date, mapping=(aes(x=contact,fill=contact))) + geom_bar()
summary(m_date$contact)
ggplot(m_date, mapping=(aes(x=month,fill=month))) + geom_bar()
summary(m_date$month)
ggplot(m_date, mapping=(aes(x=day_of_week,fill=day_of_week))) + geom_bar()
summary(m_date$day_of_week)
mm_cor_matrix <- select_if(m_date, is.numeric)
# Compute the correlation matrix
cor_matrix <- cor(mm_cor_matrix)
# Plot the correlation matrix
corrplot(cor_matrix, method = "color", type = "lower", tl.cex = 1)
final_mm_dataset <- select(m_date,-c(shifted_cons.conf.idx,pdays5,cons.conf.idx,marital,poutcome))
df <- select_if(final_mm_dataset, is.numeric)
# Compute the correlation matrix
mm_cor_matrix <- cor(df)
# Plot the correlation matrix
corrplot(mm_cor_matrix, method = "color", type = "lower", tl.cex = 1)
library(caret)
set.seed(350)
#partitioning the dataset i.e  70% train set and 30% for test set
mm_train = createDataPartition(y = final_mm_dataset$y, times = 1, p = 0.7, list = FALSE)
train_set = slice(final_mm_dataset, mm_train)
test_set = slice(final_mm_dataset, -mm_train)
model <- glm(y ~ ., data = train_set, family = binomial)
# Print the summary of the model
summary(model)
predictions <- predict(model, newdata = test_set, type = "response")
binary_predictions <- ifelse(predictions > 0.5, "yes", "no")
heart_glm <- confusionMatrix(data = as.factor(binary_predictions), reference = as.factor(test_set$y), positive = "no")
heart_glm
library(pROC)
roc_GLM <- roc(test_set$y, predictions)
print(roc_GLM)
plot(roc_GLM)
library(rpart)
library(rpart.plot)
decision_trees_mm <- rpart(y ~ ., data = train_set, method = "class")
predict_decisiontrees <- predict(decision_trees_mm, newdata = test_set, type = c("class"))
mm_DecisionTree <- confusionMatrix(data = as.factor(predict_decisiontrees), reference = as.factor(test_set$y), positive = "no")
mm_DecisionTree
decision_tree.preds <- predict(decision_trees_mm, test_set, type="prob")[, 2]
decision_tree <- roc(test_set$y, decision_tree.preds)
print(decision_tree)
plot(decision_tree)
plot(decision_tree)
rpart.plot(predict_decisiontrees)
plot(predict_decisiontrees)
plot(decision_trees_mm)
rpart.plot(decision_trees_mm)
rpart.plot(decision_trees_mm)
mm_DecisionTree
summary(m_date$duration)
ggplot(data=m_date,mapping(aes(x=age,y=duration)))+geom_point()+geom_smooth()
ggplot(data=m_date,(aes(x=age,y=duration)))+geom_point()+geom_smooth()
ggplot(data=m_date,(aes(x=duration,y=age)))+geom_point()+geom_smooth()
ggplot(data=m_date,(aes(x=nr.employed,y=age)))+geom_point()+geom_smooth()
ggplot(data=m_date,(aes(x=nr.employed,y=euribor3m)))+geom_point()+geom_line()
ggplot(data=m_date,(aes(x=cons.price.idx,y=cons.conf.idx)))+geom_point()+geom_line()
ggplot(data=m_date,(aes(x=duration,y=age)))+geom_point()+geom_line()
tinytex::install_tinytex()
getwd()
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
install.packages(tidyverse)
install.packages('tidyverse')
install.packages('ggplot2')
install.packages('rlang')
remove.packages(rlang)
install.packages("rlang")
install.packages("tidyverse")
clear
library(tidyverse)
setwd("D:/R/HEALTH SYSTEMS/day 7")
library(tidyverse)
m_date <- read.csv("MMA marketing_data_sample.csv",header = TRUE)
m_date <- read.csv("MMA Assets_Data_prac",header = TRUE)
library(tidyverse)
setwd("D:/R/HEALTH SYSTEMS/day 7")
library(tidyverse)
setwd("D:/R/HEALTH SYSTEMS/day 7")
m_date <- read.csv("MMA Assets_Data_prac",header = TRUE)
m_date <- read.csv("MMA Assets_Data_prac.csv",header = TRUE)
m_date <- read.csv("Assets_Data_prac.csv",header = TRUE)
View(m_date)
knitr::opts_chunk$set(echo = TRUE)
install.packages("FactoMineR")
install.packages("vcd")
install.packages("factoextra")
library(FactoMineR)
library(vcd)
library(factoextra)
library(tidyverse)
library(FactoMineR)
library(vcd)
library(factoextra)
Assets_data <- read.csv("Assets_Data_prac.csv",header = TRUE)
table(is.na(Assets_data))
View(Assets_data)
str(Assets_data)
Assets_famd <- FAMD(Assets_data, graph=FALSE, ncp = 33)
Assets_famd
Assets_famd
eig.val <- get_eigenvalue(Assets_famd)
head(eig.val)
fviz_screeplot(Assets_famd, ncp=33)
fviz_screeplot(Assets_famd, ncp=33)
# Coordinates of variables
head(var$coord)
var <- get_famd_var(Assets_famd)
var
# Coordinates of variables
head(var$coord)
# Cos2: quality of representation on the factore map
head(var$cos2)
# Contributions to the  dimensions
head(var$contrib)
fviz_famd_var(Assets_famd, repel = TRUE)
# Contribution to the first dimension
fviz_contrib(Assets_famd, "var", axes = 1)
# Contribution to the second dimension
fviz_contrib(Assets_famd, "var", axes = 2)
Assets_famd
eig.val <- get_eigenvalue(Assets_famd)
head(eig.val)
fviz_screeplot(Assets_famd, ncp=33)
str(Assets_data)
Assets_famd <- FAMD(Assets_data, graph=FALSE, ncp = 5)
Assets_famd
eig.val <- get_eigenvalue(Assets_famd)
head(eig.val)
fviz_screeplot(Assets_famd, ncp=33)
fviz_eig( train.pca, addlabels = TRUE, ylim = c( 0, 50))
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
library(tidyverse)
setwd("D:/R/HEALTH SYSTEMS/day 9")
Assets_data <- read.csv("clustering_data_final.csv",header = TRUE)
df <- USArrests
df <- na.omit(df)
?USArrests
view(USArrests)
view(df)
dfs <- scale(df)
head(dfs)
view(dfs)
distance <- get_dist(dfs)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
distance <- get_dist(dfs)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
k2 <- kmeans(dfs, centers = 2, nstart = 25)
str(k2)
data("iris")
dataset <- na.omit(iris)
dataset[,-5] <- scale(dataset[,-5])
validationIndex <- createDataPartition(dataset$Species, p=0.70, list=FALSE)
validationIndex <- createDataPartition(dataset$Species, p=0.70, list=FALSE)
library(caret)
validationIndex <- createDataPartition(dataset$Species, p=0.70, list=FALSE)
train <- dataset[validationIndex,] # 70% of data to training
test <- dataset[-validationIndex,] # remaining 30% for test
trainControl <- trainControl(method="repeatedcv", number=10, repeats=3)
metric <- "Accuracy"
set.seed(7)
fit.knn <- train(Species~., data=train, method="knn",
metric=metric ,trControl=trainControl)
knn.k1 <- fit.knn$bestTune # keep this Initial k for testing with knn() function in next section
print(fit.knn)
plot(fit.knn)
set.seed(7)
prediction <- predict(fit.knn, newdata = test)
cf <- confusionMatrix(prediction, test$Species)
print(cf)
fit.knn.k2 <- knn(train=train[,-5], test=test[,-5], cl=train$Species, k=knn.k2)
library(caret)
library(class)
fit.knn.k2 <- knn(train=train[,-5], test=test[,-5], cl=train$Species, k=knn.k2)
knitr::opts_chunk$set(echo = TRUE)
library(boot)
library(ggplot2)
library(boot)
library(ggplot2)
setwd("D:/SCHULE/NUMERICAL Analysis/UNIT 4")
library(boot)
library(ggplot2)
PSDS_PATH <- file.path(dirname(dirname(getwd())))
loans_income <- read.csv(file.path(PSDS_PATH, 'data', 'loans_income.csv'))
print(PSDS_PATH)
setwd("D:/SCHULE/NUMERICAL Analysis/UNIT 4")
print(PSDS_PATH)
setwd("D:/SCHULE/NUMERICAL Analysis/UNIT 4")
H
PSDS_PATH <- file.path(dirname(dirname(getwd())))
print(PSDS_PATH)
PSDS_PATH <- setwd("D:/SCHULE/NUMERICAL Analysis/UNIT 4")
print(PSDS_PATH)
loans_income <- read.csv(file.path(PSDS_PATH, 'data', 'loans_income.csv'))
loans_income <- read.csv(file.path(PSDS_PATH, 'data', 'loans_income.csv'))
View(loans_income)
View(loans_income)
loans_income <- loans_income[, 1]   # convert data frame to vector
loans_income <- loans_income[, 4]   # convert data frame to vector
loans_income <- loans_income[, 2]   # convert data frame to vector
loans_income <- loans_income[, 1]   # convert data frame to vector
loans_income <- read.csv(file.path(PSDS_PATH, 'data', 'loans_income.csv'))
loans_income <- loans_income[, 2]   # convert data frame to vector
loans_income <- loans_income[, 1]   # convert data frame to vector
sp500_px <- read.csv(file.path(PSDS_PATH, 'data', 'sp500_data.csv.gz'), row.names=1)
View(sp500_px)
View(sp500_px)
x <- seq(from=-3, to=3, length=300)
print(x)
gauss <- dnorm(x)
par(mar=c(3, 3, 0, 0)+.1)
plot(x, gauss, type='l', col='blue', xlab='', ylab='', axes=FALSE)
polygon(x, gauss, col='blue')
dev.off()
norm_samp <- rnorm(100)
par(mar=c(3, 3, 0, 0)+.1)
hist(norm_samp, axes=FALSE, col='red', main='')
dev.off()
# take a simple random sample
samp_data <- data.frame(income=sample(loans_income, 1000),
type='data_dist')
loans_income <- read.csv(file.path(PSDS_PATH, 'data', 'loans_income.csv'))
# take a simple random sample
samp_data <- data.frame(income=sample(loans_income, 1000),
type='data_dist')
loans_income <- read.csv(file.path(PSDS_PATH, 'data', 'loans_income.csv'))
View(loans_income)
View(loans_income)
# take a simple random sample
samp_data <- data.frame(income=sample(loans_income, 1000),
type='data_dist')
loans_income <- loans_income[, 1]   # convert data frame to vector
# take a simple random sample
samp_data <- data.frame(income=sample(loans_income, 1000),
type='data_dist')
# take a sample of means of 5 values
samp_mean_05 <- data.frame(
income = tapply(sample(loans_income, 1000*5),
rep(1:1000, rep(5, 1000)), FUN=mean),
type = 'mean_of_5')
# take a sample of means of 20 values
samp_mean_20 <- data.frame(
income = tapply(sample(loans_income, 1000*20),
rep(1:1000, rep(20, 1000)), FUN=mean),
type = 'mean_of_20')
View(samp_mean_20)
View(samp_mean_20)
View(samp_data)
View(samp_data)
View(samp_mean_20)
View(samp_mean_20)
View(samp_mean_05)
View(samp_mean_05)
# bind the data.frames and convert type to a factor
income <- rbind(samp_data, samp_mean_05, samp_mean_20)
View(income)
View(income)
income$type <- factor(income$type,
levels=c('data_dist', 'mean_of_5', 'mean_of_20'),
labels=c('Data', 'Mean of 5', 'Mean of 20'))
view(income$type)
View(income$type)
ggplot(income, aes(x=income)) +
geom_histogram(bins=40) +
facet_grid(type ~ .)
data()
